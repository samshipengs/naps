{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time \n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "from functools import partial\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from utils import ignore_warnings, load_data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 1.4 s, total: 20.1 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# nrows = 10000\n",
    "nrows = None\n",
    "train = load_data('train', nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-28 11:21:44 - utils - preprocess_sessions - INFO] Cliping session dataframe up to last click out (if there is clickout)\n"
     ]
    }
   ],
   "source": [
    "from clean_session import preprocess_sessions\n",
    "train = preprocess_sessions(train,data_source='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the rows that is clickout\n",
    "is_clickout = train.action_type == 'clickout item'\n",
    "# # and it is not nan\n",
    "# not_na = train.re.notna()\n",
    "# and the impressions are not nans\n",
    "imp_not_na = train.impressions.notna()\n",
    "# only select the ones with 25 lens \n",
    "train['nimp'] = train.impressions.str.split('|').str.len()\n",
    "twenty_five = train['nimp'] == 25\n",
    "\n",
    "select_mask = is_clickout & imp_not_na & twenty_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[select_mask].reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['current_filters'].isna(), 'current_filters'] = 'no_filter'\n",
    "train.loc[train['reference'].isna(), 'reference'] = 'no_reference'\n",
    "\n",
    "train['cfs'] = train['current_filters'].str.split('|')\n",
    "train['imps'] = train['impressions'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before:', train.shape)\n",
    "train = train[train.reference.notna()].reset_index(drop=True)\n",
    "print('after:', train.shape)\n",
    "train = train[train.imps.str.len()==25].reset_index(drop=True)\n",
    "def assign_target(row):\n",
    "    ref = row.reference\n",
    "    imp = row.imps\n",
    "    if ref in imp:\n",
    "        return imp.index(ref)\n",
    "    else:\n",
    "        return 25\n",
    "#         return -1\n",
    "train['target'] = train.apply(assign_target, axis=1)\n",
    "# remove the target 25 (i.e. not appearing in the list)\n",
    "print('before:', train.shape)\n",
    "train = train[train.target != 25].reset_index(drop=True)\n",
    "print('after:', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./cache/hotel_2vec/model.bin')\n",
    "\n",
    "def encoding_depth(imps):\n",
    "    return np.array([model.wv[i] for i in imps])[None, :, :]\n",
    "\n",
    "def encoding(imps):\n",
    "    return np.array([model.wv[i] for i in imps])\n",
    "\n",
    "def encoding_column(imps):\n",
    "    return np.array([model.wv[i] for i in imps])[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "train['imps'] = train.imps.apply(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode city, platform and device\n",
    "def categorize(df, cols):\n",
    "    for col in cols:\n",
    "        print('converting', col)\n",
    "        unique_values = df[col].unique()\n",
    "        mapping = {v: k for k, v in enumerate(unique_values)}\n",
    "        df[col] = df[col].map(mapping)\n",
    "        \n",
    "categorize(train, ['city', 'platform', 'device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.device.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['device'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[['session_id', 'timestamp', 'reference', 'imps', 'city', 'device', 'platform', 'prices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prices'] = train.prices.str.split('|')\n",
    "train['prices'] = train['prices'].apply(lambda prices: [int(p) for p in prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prices = train.prices.values\n",
    "all_prices = [j for i in all_prices for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# _ = plt.hist(all_prices, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.hist(np.log1p(all_prices), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.hist(train_prices, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_mu = np.mean(all_prices)\n",
    "price_sd = np.std(all_prices)\n",
    "prices = np.array(list(train.prices.values))\n",
    "prices = (prices - price_mu)/price_sd\n",
    "del train['prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions = np.array(list(train.imps.values))\n",
    "del train['imps']\n",
    "\n",
    "cities = train.city.values\n",
    "ncity = train.city.nunique()\n",
    "del train['city']\n",
    "\n",
    "platforms = train.platform.values\n",
    "nplat = train.platform.nunique()\n",
    "\n",
    "del train['platform']\n",
    "sids = train.session_id.values\n",
    "del train['session_id']\n",
    "targets = train.target.values\n",
    "del train['target']\n",
    "devices = train[['device_1', 'device_2']].values\n",
    "del train['device_1'], train['device_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)        \n",
    "        print('Testing loss: {0:.4f}, acc: {1:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "\n",
    "# def mrr(y_true, y_pred):\n",
    "# #     return K.mean(y_pred)\n",
    "#     y_true_item = K.argmax(y_true, axis=-1)\n",
    "#     print(y_true_item)\n",
    "    \n",
    "#     y_pred_sorted = tf.nn.top_k(input, k=25, sorted=True).indices\n",
    "#     return K.mean(1/tf.where(y_pred_sorted==y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Activation, concatenate, Dense, Dropout, Embedding, Input, Reshape, Flatten, Conv1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "# split_per = 0.1\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for trn_ind, val_ind in skf.split(targets, targets):\n",
    "    trn_imp, val_imp = impressions[trn_ind], impressions[val_ind]\n",
    "    trn_price, val_price = prices[trn_ind], prices[val_ind]\n",
    "    trn_city, val_city = cities[trn_ind], cities[val_ind]\n",
    "    trn_plat, val_plat = platforms[trn_ind], platforms[val_ind]\n",
    "    trn_dev, val_dev = devices[trn_ind], devices[val_ind]\n",
    "    \n",
    "    y_trn, y_val = targets[trn_ind], targets[val_ind]\n",
    "    \n",
    "    # build model\n",
    "    # impressions\n",
    "    imp_input = Input(shape=(25, 100))\n",
    "    imp_conv = Conv1D(16, kernel_size=3, activation='relu')(imp_input)\n",
    "    imp_flatten = Flatten()(imp_conv)\n",
    "    # city embeddings\n",
    "    city_input = Input(shape = (1, ), dtype = 'int32')\n",
    "    city_embedding = Embedding(ncity, 20, input_length=1)(city_input)\n",
    "    city_embedding = Flatten()(city_embedding)\n",
    "    \n",
    "    # platform input \n",
    "    plat_input = Input(shape = (1, ), dtype = 'int32')\n",
    "    plat_embedding = Embedding(nplat, 10, input_length=1)(plat_input)\n",
    "    plat_embedding = Flatten()(plat_embedding)\n",
    "                       \n",
    "    # device\n",
    "    device_input =  Input(shape = (2, ))\n",
    "    \n",
    "    # price input\n",
    "    price_input =  Input(shape = (25, ))\n",
    "    \n",
    "    # concatenate\n",
    "    concat1 = concatenate([imp_flatten, price_input])\n",
    "    concat1 = Dense(units=30, activation='relu')(concat1)\n",
    "    concat1 = Dropout(0.2)(concat1)\n",
    "    concat2 = concatenate([concat1, city_embedding, plat_embedding, device_input])\n",
    "    concat2 = Dropout(0.2)(concat2)\n",
    "    \n",
    "    h = Dense(units=30, activation='relu')(concat2)\n",
    "    output_layer = Dense(25, activation='softmax')(h)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[imp_input, city_input, plat_input, device_input, price_input], \n",
    "                  outputs=output_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "#     model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics=['accuracy', mrr])\n",
    "# model.compile(optimizer = opt, loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # from clr import CyclicLR\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "    from datetime import datetime as dt\n",
    "    model_file = 'test.model'\n",
    "\n",
    "    callbacks = [ModelCheckpoint(model_file, save_best_only=True, verbose=1)]\n",
    "    # callbacks.append(EarlyStopping(patience=150, verbose=1))\n",
    "    # callbacks.append(ReduceLROnPlateau(factor=0.5, patience=20, min_lr=5e-4, verbose=1))\n",
    "    log_dir = \"logs/{}\".format(dt.now().strftime('%m-%d-%H-%M'))\n",
    "    # tb = TensorBoard(log_dir=log_dir, histogram_freq=2, write_graph=True, write_grads=True, write_images=True,\n",
    "    #                  embeddings_freq=10, embeddings_layer_names=['embedding_1'], embeddings_data=next(val_gen))\n",
    "    tb = TensorBoard(log_dir=log_dir, write_graph=True, write_grads=True)\n",
    "    callbacks.append(tb)\n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 128\n",
    "    n_epochs = 30\n",
    "    # keras requires 0, 1 binary label input\n",
    "    from keras.utils import to_categorical\n",
    "    train_y_binary = to_categorical(y_trn)\n",
    "    val_y_binary = to_categorical(y_val)\n",
    "\n",
    "    history = model.fit([trn_imp, trn_city, trn_plat, trn_dev, trn_price], \n",
    "                        train_y_binary, \n",
    "                        epochs=n_epochs, \n",
    "                        batch_size=batch_size,\n",
    "                        verbose = 2, \n",
    "                        shuffle = True,\n",
    "                        callbacks=callbacks+[TestCallback(([val_imp, val_city, val_plat, val_dev, val_price],\n",
    "                                                           val_y_binary))])\n",
    "    \n",
    "    # make predictions\n",
    "    trn_pred = model.predict([trn_imp, trn_city, trn_plat, trn_dev, trn_price])\n",
    "    trn_mrr = np.mean(1/(np.where(np.argsort(trn_pred)[:, ::-1] == y_trn.reshape(-1, 1))[1]+1))\n",
    "    \n",
    "    val_pred = model.predict([val_imp, val_city, val_plat, val_dev, val_price])\n",
    "    val_mrr = np.mean(1/(np.where(np.argsort(val_pred)[:, ::-1] == y_val.reshape(-1, 1))[1]+1))\n",
    "    print(f'train mrr: {trn_mrr:.2f} | val mrr: {val_mrr:.2f}')\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(val_pred)[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(1/(np.where(np.argsort(val_pred)[:, ::-1] == y_val.reshape(-1, 1))[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.argsort(val_pred)[:, ::-1] == y_val.reshape(-1, 1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(val_pred)[:, ::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.argsort(val_pred)[:, ::-1][0]==y_val.reshape(-1, 1))[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
