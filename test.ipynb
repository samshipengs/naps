{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time \n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "'''/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:51: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
    "  return getattr(obj, method)(*args, **kwds)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "!ls -lthr data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# nrows = 10000\n",
    "nrows = None\n",
    "train = pd.read_csv(data_path+'train.csv', nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pshape(df):\n",
    "    print(f'df len: {df.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pshape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_path+'test.csv', nrows=1000)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_click_session_ids = test[test.impressions.notnull()].session_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ts = np.random.choice(test_click_session_ids, 1)\n",
    "# test[test.session_id==ts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_click_ids = train[train.impressions.notnull()].session_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = np.random.choice(train_click_ids, 1)\n",
    "# train[train.session_id==ts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.groupby('session_id').apply(lambda x: x.iloc[-1]['reference']).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.groupby('session_id').apply(lambda x: x.iloc[-1]['impressions']).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clip sessions off to last click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get all rows upto the last clickout action (some rows has reference but it's not clickout action)\n",
    "def up_to_last_click(grp):\n",
    "    check = grp.action_type == 'clickout item'\n",
    "    if check.sum() != 0:\n",
    "        return grp.iloc[:np.argwhere(check)[-1][0]+1]\n",
    "    else:\n",
    "        return grp\n",
    "        \n",
    "train = train.groupby('session_id').apply(up_to_last_click).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get utc timestamp\n",
    "train['ts'] = train['timestamp'].apply(lambda t: datetime.datetime.utcfromtimestamp(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# only look at sessions with clickouts (for now)\n",
    "# first filter out sessions that does not have a click-out\n",
    "def check_clickout(grp):\n",
    "     # sessions has clickouts\n",
    "    has_clickout = 'clickout item' in grp['action_type'].unique()\n",
    "    # last row has reference and it's not nan\n",
    "    has_ref = ((grp['action_type'].iloc[-1] == 'clickout item') & \n",
    "               (grp.iloc[-1][['impressions', 'reference', 'prices']].isna().sum()==0))\n",
    "    return has_clickout & has_ref\n",
    "    \n",
    "clicked = train.groupby('session_id').apply(check_clickout)\n",
    "click_session_ids = clicked[clicked].index\n",
    "# filter\n",
    "train = train[train.session_id.isin(click_session_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # only look at sessions with clickouts (for now)\n",
    "# # first filter out sessions that does not have a click-out\n",
    "# def check_clickout(grp):\n",
    "#      # sessions has clickouts\n",
    "#     has_clickout = 'clickout item' in grp['action_type'].unique()\n",
    "#     # last row has reference and it's not nan\n",
    "#     has_ref = ((grp['action_type'].iloc[-1] == 'clickout item') & \n",
    "#                (pd.notnull(grp.iloc[-1]['impressions'])) &\n",
    "#                (pd.notnull(grp.iloc[-1]['reference'])) &\n",
    "#                (pd.notnull(grp.iloc[-1]['prices'])))\n",
    "#     return has_clickout & has_ref\n",
    "    \n",
    "# clicked = train.groupby('session_id').apply(check_clickout)\n",
    "# click_session_ids = clicked[clicked].index\n",
    "# # filter\n",
    "# train = train[train.session_id.isin(click_session_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pshape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = train.groupby('session_id')\n",
    "# for i, j in d:\n",
    "#     print(j.head())\n",
    "#     print('='*20)\n",
    "#      # sessions has clickouts\n",
    "#     has_clickout = 'clickout item' in j['action_type'].unique()\n",
    "#     print(has_clickout)\n",
    "#     # last row has reference and it's not nan\n",
    "#     has_ref = ((j['action_type'].iloc[-1] == 'clickout item') & \n",
    "#                (pd.notnull(j.iloc[-1]['impressions'])) &\n",
    "#                (pd.notnull(j.iloc[-1]['reference'])))\n",
    "#     print(has_ref)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "meta = pd.read_csv(data_path+'item_metadata.csv', nrows=nrows)\n",
    "meta['properties'] = meta['properties'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# checkout properties of items\n",
    "def get_property_count(row):\n",
    "    return len(row.split('|'))\n",
    "\n",
    "item_p_ctn = meta['properties'].apply(get_property_count)\n",
    "item_p_ctn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_property(row):\n",
    "    return row.lower().split('|')\n",
    "meta['ps'] = meta['properties'].apply(get_property)\n",
    "# numer of properties\n",
    "meta['nprop'] = meta.ps.str.len()\n",
    "# star ratings\n",
    "meta['star'] = meta.properties.str.extract('[\\|](\\d) star')\n",
    "meta['star'] = meta['star'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create rating columns\n",
    "ratings = ['good rating', 'satisfactory rating', 'excellent rating']\n",
    "for r in ratings:\n",
    "    meta[r.replace(' ', '_')] = meta.properties.str.findall(f'\\|{r}').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = (meta[['item_id', 'nprop', 'star', 'good_rating', 'satisfactory_rating', 'excellent_rating']]\n",
    "        .set_index('item_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create session features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # find out if same customers have multiple sessions\n",
    "# s = train.drop_duplicates(subset=['user_id', 'session_id'])\n",
    "# s.session_id.duplicated().sum()\n",
    "# # seems like not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.current_filters[:1000].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_filters(x):\n",
    "    if type(x) == str or type(x) == list:\n",
    "        return x.split('|')\n",
    "    else:\n",
    "        return np.nan\n",
    "def get_impressions(x):\n",
    "    if type(x) == str:\n",
    "        return x.split('|')\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "train['filters'] = train.current_filters.str.split('|')\n",
    "train['nfilters'] = train.filters.str.len()\n",
    "train['imps_list'] = train.impressions.str.split('|')\n",
    "nn_mask = train['imps_list'].notnull()\n",
    "train.loc[nn_mask, 'imps_list'] = train.loc[nn_mask, 'imps_list'].apply(lambda x: [int(i) for i in x])\n",
    "train['nimps'] = train.imps_list.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.nimps.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no switch of devices during session\n",
    "# (train.groupby('session_id')['device'].nunique()!=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # differnet city during session\n",
    "# (train.groupby('session_id')['city'].nunique()!=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# some custom funcs used in agggregation\n",
    "def mean_dwell_time(x):\n",
    "    if len(x) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(np.diff(np.sort(x)))\n",
    "    \n",
    "def var_dwell_time(x):\n",
    "    if len(x) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.var(np.diff(np.sort(x)))\n",
    "    \n",
    "def get_first(x):\n",
    "    return x.iloc[0]\n",
    "\n",
    "def get_last(x):\n",
    "    return x.iloc[-1]\n",
    "\n",
    "def n_clickouts(x):\n",
    "    return (x=='clickout item').sum()\n",
    "\n",
    "def click_rel_pos_avg(x):\n",
    "    return np.mean(np.argwhere((x=='clickout item')))/len(x)\n",
    "\n",
    "def ptp(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "\n",
    "# define some aggs\n",
    "# session_aggs = {'timestamp': [np.ptp, mean_dwell_time, var_dwell_time],\n",
    "session_aggs = {'timestamp': [ptp, mean_dwell_time, var_dwell_time],\n",
    "                'step': ['max'],\n",
    "                'action_type': ['nunique', n_clickouts, click_rel_pos_avg],\n",
    "                'city': ['nunique', get_first],\n",
    "                'platform': [get_first],\n",
    "                'device': [get_first],\n",
    "                'nfilters': ['mean', 'max', 'min', get_last],\n",
    "                'nimps': ['max']\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_grp = train.groupby('session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# import os.path\n",
    "session_file = 'session_fts.csv'\n",
    "if os.path.isfile(session_file):\n",
    "    session_fts = pd.read_csv(session_file)\n",
    "else:\n",
    "    session_fts = session_grp.agg(session_aggs)\n",
    "    session_fts.columns = ['_'.join(col).strip() for col in session_fts.columns.values]\n",
    "    session_fts.to_csv(session_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_fts.columns.values\n",
    "session_fts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train.session_id=='62991f7c78f27']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clickout features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def get_session_item_pairs(args):\n",
    "    # grab the args\n",
    "    gids, session_df, meta_df = args\n",
    "    # selecting the assigned session ids and grouping on session level\n",
    "    grps = (session_df[session_df['session_id'].isin(gids)]\n",
    "            .reset_index(drop=True)\n",
    "            .groupby('session_id'))\n",
    "    \n",
    "    # use apply to compute session level features\n",
    "    session_compute_func = partial(compute_session_item_pair, meta_df=meta_df)\n",
    "    session_features = grps.apply(session_compute_func)\n",
    "    \n",
    "    return session_features\n",
    "        \n",
    "    \n",
    "# def compute_session_item_pair(session_df, g_id, buy_df):\n",
    "def compute_session_item_pair(session_df, meta_df):\n",
    "    sdf = session_df.copy()\n",
    "#     with Timer('select_rows', profile) as t:\n",
    "    last_row = sdf.iloc[-1]\n",
    "    above = sdf.iloc[:-1]\n",
    "#     with Timer('exclude_nans', profile) as t:\n",
    "    # get previous appeard impressions\n",
    "    prev = above[above['impressions'].notnull()]\n",
    "#     with Timer('get_imp_list', profile) as t:\n",
    "    prev_imps = prev['imps_list']\n",
    "    unique_imps = [j for i in prev_imps for j in i]\n",
    "\n",
    "#     with Timer('get_price', profile) as t:\n",
    "    imp_l = last_row['imps_list']\n",
    "#     try:\n",
    "    prices = last_row['prices'].split('|')\n",
    "#     except:\n",
    "#         print(last_row['prices'], last_row)\n",
    "    prices = [int(p) for p in prices]\n",
    "    # whether the impression appeared before\n",
    "    appeared = [int(i in unique_imps) for i in imp_l]\n",
    "    # the location of the impression\n",
    "    locs = list(range(len(imp_l)))\n",
    "\n",
    "#     with Timer('create_df', profile) as t:\n",
    "# build the df\n",
    "    result = pd.DataFrame({'appeared': appeared, 'location': locs, 'price': prices}, index=imp_l)\n",
    "    result.index.name = 'item_id'\n",
    "#     with Timer('rel_price_rank', profile) as t:\n",
    "    price_ind = np.argsort(result['price'].values) + 1\n",
    "    result['rel_price_rank'] = price_ind/len(imp_l)\n",
    "#         result['rel_price_rank'] = result[['location', 'price']].sort_values(by='price')['location']/len(imp_l)\n",
    "\n",
    "#     with Timer('compute_mean_median', profile) as t:\n",
    "    result['price_mean'] = np.mean(result['price'])\n",
    "    result['price_median'] = np.median(result['price'])\n",
    "\n",
    "#     with Timer('compute_diff', profile) as t: \n",
    "    result_price = result['price'].values\n",
    "    result_price_mean = result['price_mean'].values \n",
    "    result_price_median = result['price_median'].values\n",
    "\n",
    "    result['diff_mean'] = result_price - result_price_mean\n",
    "    result['diff_median'] = result_price - result_price_median\n",
    "    result['diff_mean_rel'] = (result_price - result_price_mean)/result_price\n",
    "    result['diff_median_rel'] = (result_price - result_price_median)/result_price\n",
    "\n",
    "#     with Timer('join', profile) as t:\n",
    "    # fetch the meta data\n",
    "    result = result.join(meta_df, on='item_id')\n",
    "#     with Timer('create_mean_meta1', profile) as t:\n",
    "    result['star_mean'] = np.mean(result['star'].values)\n",
    "#     with Timer('create_mean_meta2', profile) as t:\n",
    "    result['gr_mean'] = np.mean(result['good_rating'].values)\n",
    "#     with Timer('create_mean_meta3', profile) as t:\n",
    "    result['sr_mean'] = np.mean(result['satisfactory_rating'].values)\n",
    "#     with Timer('create_mean_meta4', profile) as t:\n",
    "    result['er_mean'] = np.mean(result['excellent_rating'].values)\n",
    "#     with Timer('create_mean_meta5', profile) as t:\n",
    "    result.reset_index(inplace=True)\n",
    "\n",
    "#     with Timer('create target', profile) as t:\n",
    "    # get target\n",
    "    ref = int(last_row['reference'])\n",
    "    result['target'] = (result['item_id'].values == ref).astype(int)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 2) dwell time for each clickout\n",
    "# 3) the rating and star and nproperty -> mean and median for \n",
    "#     the other impressions in list (or the quantile of these and prices)\n",
    "# 4) location and relative location in the impressions list\n",
    "\n",
    "\n",
    "def generate_session_item_pairs(sessions_df, meta_df, nprocs=None):\n",
    "    t1 = time.time()\n",
    "    if nprocs is None:\n",
    "        nprocs = mp.cpu_count() - 1 \n",
    "        print('Using {} cores'.format(nprocs))\n",
    "\n",
    "    sids = sessions_df.session_id.unique()\n",
    "    \n",
    "    pairs = []\n",
    "    # create iterator to pass in args\n",
    "    def args_gen():\n",
    "        for i in range(nprocs):\n",
    "            yield (sids[range(i, len(sids), nprocs)], sessions_df, meta_df)\n",
    "    \n",
    "    # init multiprocessing pool\n",
    "    pool = mp.Pool(nprocs)\n",
    "    for pair in pool.map(get_session_item_pairs, args_gen()):\n",
    "        pairs.append(pair)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Done genearting, total time took: {0:.2f}mins'.format((time.time()-t1)/60))\n",
    "\n",
    "    return pd.concat(pairs, axis=0)#, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result_df = generate_session_item_pairs(train[train.session_id.isin(sids)], meta, nprocs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result_df = generate_session_item_pairs(train[:10000], meta, nprocs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_df = generate_session_item_pairs(train, meta, nprocs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./data/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result_df = result_df.reset_index(level='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# join on session features\n",
    "result_df = result_df.set_index('session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final = result_df.join(session_fts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do:\n",
    "\n",
    "1) check the time range of train vs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
