{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time \n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "from functools import partial\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from utils import ignore_warnings, load_data\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # nrows = 10000\n",
    "# nrows = None\n",
    "# train = load_data('train', nrows=nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-29 20:56:59 - utils - preprocess_sessions - INFO] Load from existing file: ./cache/preprocessed_data.snappy\n"
     ]
    }
   ],
   "source": [
    "from clean_session import preprocess_sessions\n",
    "# train = preprocess_sessions(train,data_source='data')\n",
    "train = preprocess_sessions(None,data_source='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13034626, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the rows that is clickout\n",
    "is_clickout = train.action_type == 'clickout item'\n",
    "# # and it is not nan\n",
    "# not_na = train.re.notna()\n",
    "# and the impressions are not nans\n",
    "imp_not_na = train.impressions.notna()\n",
    "# only select the ones with 25 lens \n",
    "train['nimp'] = train.impressions.str.split('|').str.len()\n",
    "twenty_five = train['nimp'] == 25\n",
    "\n",
    "select_mask = is_clickout & imp_not_na & twenty_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232016, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[select_mask].reset_index(drop=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London, United Kingdom    0.018555\n",
       "Tokyo, Japan              0.032619\n",
       "New York, USA             0.045206\n",
       "Paris, France             0.057427\n",
       "Las Vegas, USA            0.068185\n",
       "Name: city, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get only common cities\n",
    "train_last = train.groupby('session_id').last().reset_index()\n",
    "city_counts = train_last.city.value_counts()\n",
    "city_counts_cs = city_counts.cumsum()/(city_counts.sum())\n",
    "city_counts_cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.9\n",
    "above_th = city_counts_cs[city_counts_cs<th]\n",
    "common_cities = above_th.index.values\n",
    "train = train[train.city.isin(common_cities)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1129006, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20366, 3042)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last.city.nunique(), train.city.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.426596052873127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3042**0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['current_filters'].isna(), 'current_filters'] = 'no_filter'\n",
    "train.loc[train['reference'].isna(), 'reference'] = 'no_reference'\n",
    "\n",
    "train['cfs'] = train['current_filters'].str.split('|')\n",
    "train['imps'] = train['impressions'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (1129006, 15)\n",
      "after: (1129006, 15)\n",
      "before: (1129006, 16)\n",
      "after: (1128388, 16)\n"
     ]
    }
   ],
   "source": [
    "print('before:', train.shape)\n",
    "train = train[train.reference.notna()].reset_index(drop=True)\n",
    "print('after:', train.shape)\n",
    "train = train[train.imps.str.len()==25].reset_index(drop=True)\n",
    "def assign_target(row):\n",
    "    ref = row.reference\n",
    "    imp = row.imps\n",
    "    if ref in imp:\n",
    "        return imp.index(ref)\n",
    "    else:\n",
    "        return 25\n",
    "#         return -1\n",
    "train['target'] = train.apply(assign_target, axis=1)\n",
    "# remove the target 25 (i.e. not appearing in the list)\n",
    "print('before:', train.shape)\n",
    "train = train[train.target != 25].reset_index(drop=True)\n",
    "print('after:', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>step</th>\n",
       "      <th>action_type</th>\n",
       "      <th>reference</th>\n",
       "      <th>platform</th>\n",
       "      <th>city</th>\n",
       "      <th>device</th>\n",
       "      <th>current_filters</th>\n",
       "      <th>impressions</th>\n",
       "      <th>prices</th>\n",
       "      <th>nimp</th>\n",
       "      <th>cfs</th>\n",
       "      <th>imps</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WT30CXPIG450</td>\n",
       "      <td>00000510f1adc</td>\n",
       "      <td>1541064087</td>\n",
       "      <td>1</td>\n",
       "      <td>clickout item</td>\n",
       "      <td>7281198</td>\n",
       "      <td>IN</td>\n",
       "      <td>Ganpatipule, India</td>\n",
       "      <td>desktop</td>\n",
       "      <td>no_filter</td>\n",
       "      <td>2661832|9222426|7051844|4079190|5752778|468398...</td>\n",
       "      <td>46|26|16|38|12|20|21|27|13|21|36|9|144|19|8|19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[no_filter]</td>\n",
       "      <td>[2661832, 9222426, 7051844, 4079190, 5752778, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITFOTN2IT5P</td>\n",
       "      <td>00003f3b20954</td>\n",
       "      <td>1541097696</td>\n",
       "      <td>1</td>\n",
       "      <td>clickout item</td>\n",
       "      <td>979325</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Manga, Spain</td>\n",
       "      <td>mobile</td>\n",
       "      <td>no_filter</td>\n",
       "      <td>87132|886881|486611|979325|87173|87175|149508|...</td>\n",
       "      <td>330|187|437|159|499|324|476|381|424|159|144|19...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>[no_filter]</td>\n",
       "      <td>[87132, 886881, 486611, 979325, 87173, 87175, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id     session_id   timestamp  step    action_type reference  \\\n",
       "0  WT30CXPIG450  00000510f1adc  1541064087     1  clickout item   7281198   \n",
       "1  CITFOTN2IT5P  00003f3b20954  1541097696     1  clickout item    979325   \n",
       "\n",
       "  platform                city   device current_filters  \\\n",
       "0       IN  Ganpatipule, India  desktop       no_filter   \n",
       "1       ES     La Manga, Spain   mobile       no_filter   \n",
       "\n",
       "                                         impressions  \\\n",
       "0  2661832|9222426|7051844|4079190|5752778|468398...   \n",
       "1  87132|886881|486611|979325|87173|87175|149508|...   \n",
       "\n",
       "                                              prices  nimp          cfs  \\\n",
       "0  46|26|16|38|12|20|21|27|13|21|36|9|144|19|8|19...  25.0  [no_filter]   \n",
       "1  330|187|437|159|499|324|476|381|424|159|144|19...  25.0  [no_filter]   \n",
       "\n",
       "                                                imps  target  \n",
       "0  [2661832, 9222426, 7051844, 4079190, 5752778, ...       6  \n",
       "1  [87132, 886881, 486611, 979325, 87173, 87175, ...       3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('./cache/hotel_2vec/model.bin')\n",
    "\n",
    "def encoding_depth(imps):\n",
    "    return np.array([model.wv[i] for i in imps])[None, :, :]\n",
    "\n",
    "def encoding(imps):\n",
    "    return np.array([model.wv[i] for i in imps])\n",
    "\n",
    "def encoding_column(imps):\n",
    "    return np.array([model.wv[i] for i in imps])[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 s, sys: 2.21 s, total: 43.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train['imps'] = train.imps.apply(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting city\n",
      "converting platform\n",
      "converting device\n"
     ]
    }
   ],
   "source": [
    "# encode city, platform and device\n",
    "def categorize(df, cols):\n",
    "    for col in cols:\n",
    "        print('converting', col)\n",
    "        unique_values = df[col].unique()\n",
    "        mapping = {v: k for k, v in enumerate(unique_values)}\n",
    "        df[col] = df[col].map(mapping)\n",
    "        \n",
    "categorize(train, ['city', 'platform', 'device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.device.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['device'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[['session_id', 'timestamp', 'reference', 'imps', 'city', 'device', 'platform', 'prices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128388, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prices'] = train.prices.str.split('|')\n",
    "train['prices'] = train['prices'].apply(lambda prices: [int(p) for p in prices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prices = train.prices.values\n",
    "all_prices = [j for i in all_prices for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# _ = plt.hist(all_prices, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.hist(np.log1p(all_prices), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.hist(train_prices, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_mu = np.mean(all_prices)\n",
    "price_sd = np.std(all_prices)\n",
    "prices = np.array(list(train.prices.values))\n",
    "prices = (prices - price_mu)/price_sd\n",
    "del train['prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.20784389766641"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions = np.array(list(train.imps.values))\n",
    "del train['imps']\n",
    "\n",
    "cities = train.city.values\n",
    "ncity = train.city.nunique()\n",
    "del train['city']\n",
    "\n",
    "platforms = train.platform.values\n",
    "nplat = train.platform.nunique()\n",
    "\n",
    "del train['platform']\n",
    "sids = train.session_id.values\n",
    "del train['session_id']\n",
    "targets = train.target.values\n",
    "del train['target']\n",
    "devices = train[['device_1', 'device_2']].values\n",
    "del train['device_1'], train['device_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)        \n",
    "        print('Testing loss: {0:.4f}, acc: {1:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "\n",
    "# def mrr(y_true, y_pred):\n",
    "# #     return K.mean(y_pred)\n",
    "#     y_true_item = K.argmax(y_true, axis=-1)\n",
    "#     print(y_true_item)\n",
    "    \n",
    "#     y_pred_sorted = tf.nn.top_k(input, k=25, sorted=True).indices\n",
    "#     return K.mean(1/tf.where(y_pred_sorted==y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 21, 16)       8016        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 21, 16)       64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 336)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 361)          0           flatten_1[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 361)          1444        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           10860       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 8)         24336       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 3)         165         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 43)           0           dropout_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 43)           172         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 43)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           1320        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 25)           775         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,152\n",
      "Trainable params: 46,312\n",
      "Non-trainable params: 840\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import concatenate, Dense, Dropout, Embedding, Input, Flatten, Conv1D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "# split_per = 0.1\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for trn_ind, val_ind in skf.split(targets, targets):\n",
    "    trn_imp, val_imp = impressions[trn_ind], impressions[val_ind]\n",
    "    trn_price, val_price = prices[trn_ind], prices[val_ind]\n",
    "    trn_city, val_city = cities[trn_ind], cities[val_ind]\n",
    "    trn_plat, val_plat = platforms[trn_ind], platforms[val_ind]\n",
    "    trn_dev, val_dev = devices[trn_ind], devices[val_ind]\n",
    "    \n",
    "    # TEMP\n",
    "#     del impressions, prices, cities, platforms, devices\n",
    "#     gc.collect()\n",
    "    \n",
    "    y_trn, y_val = targets[trn_ind], targets[val_ind]\n",
    "    \n",
    "    # build model\n",
    "    # impressions\n",
    "    imp_input = Input(shape=(25, 100))\n",
    "    imp_conv = Conv1D(16, kernel_size=5, activation='relu')(imp_input)\n",
    "    imp_conv = BatchNormalization()(imp_conv)\n",
    "    imp_flatten = Flatten()(imp_conv)\n",
    "    # city embeddings\n",
    "    city_input = Input(shape = (1, ), dtype = 'int32')\n",
    "    city_embedding = Embedding(ncity, 8, input_length=1)(city_input)\n",
    "    city_embedding = Flatten()(city_embedding)\n",
    "    \n",
    "    # platform input \n",
    "    plat_input = Input(shape = (1, ), dtype = 'int32')\n",
    "    plat_embedding = Embedding(nplat, 3, input_length=1)(plat_input)\n",
    "    plat_embedding = Flatten()(plat_embedding)\n",
    "                       \n",
    "    # device\n",
    "    device_input =  Input(shape = (2, ))\n",
    "    \n",
    "    # price input\n",
    "    price_input =  Input(shape = (25, ))\n",
    "    \n",
    "    # concatenate\n",
    "    concat1 = concatenate([imp_flatten, price_input])\n",
    "    concat1 = BatchNormalization()(concat1)\n",
    "    concat1 = Dense(units=30, activation='relu')(concat1)\n",
    "    concat1 = Dropout(0.2)(concat1)\n",
    "    concat2 = concatenate([concat1, city_embedding, plat_embedding, device_input])\n",
    "    concat2 = BatchNormalization()(concat2)\n",
    "    concat2 = Dropout(0.2)(concat2)\n",
    "    \n",
    "    h = Dense(units=30, activation='relu')(concat2)\n",
    "    output_layer = Dense(25, activation='softmax')(h)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[imp_input, city_input, plat_input, device_input, price_input], \n",
    "                  outputs=output_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "#     model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics=['accuracy', mrr])\n",
    "# model.compile(optimizer = opt, loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # from clr import CyclicLR\n",
    "    from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "    from datetime import datetime as dt\n",
    "    model_file = 'test.model'\n",
    "\n",
    "    callbacks = [ModelCheckpoint(model_file, save_best_only=True, verbose=1)]\n",
    "    # callbacks.append(EarlyStopping(patience=150, verbose=1))\n",
    "    # callbacks.append(ReduceLROnPlateau(factor=0.5, patience=20, min_lr=5e-4, verbose=1))\n",
    "    log_dir = \"logs/{}\".format(dt.now().strftime('%m-%d-%H-%M'))\n",
    "    # tb = TensorBoard(log_dir=log_dir, histogram_freq=2, write_graph=True, write_grads=True, write_images=True,\n",
    "    #                  embeddings_freq=10, embeddings_layer_names=['embedding_1'], embeddings_data=next(val_gen))\n",
    "    tb = TensorBoard(log_dir=log_dir, write_graph=True, write_grads=True)\n",
    "    callbacks.append(tb)\n",
    "\n",
    "    \n",
    "    \n",
    "    batch_size = 256\n",
    "    n_epochs = 300\n",
    "    # keras requires 0, 1 binary label input\n",
    "    from keras.utils import to_categorical\n",
    "    train_y_binary = to_categorical(y_trn)\n",
    "    val_y_binary = to_categorical(y_val)\n",
    "\n",
    "    history = model.fit([trn_imp, trn_city, trn_plat, trn_dev, trn_price], \n",
    "                        train_y_binary, \n",
    "                        epochs=n_epochs, \n",
    "                        batch_size=batch_size,\n",
    "                        verbose = 2, \n",
    "                        shuffle = True,\n",
    "                        callbacks=callbacks+[TestCallback(([val_imp, val_city, val_plat, val_dev, val_price],\n",
    "                                                           val_y_binary))])\n",
    "    \n",
    "    # make predictions\n",
    "    trn_pred = model.predict([trn_imp, trn_city, trn_plat, trn_dev, trn_price])\n",
    "    trn_mrr = np.mean(1/(np.where(np.argsort(trn_pred)[:, ::-1] == y_trn.reshape(-1, 1))[1]+1))\n",
    "    \n",
    "    val_pred = model.predict([val_imp, val_city, val_plat, val_dev, val_price])\n",
    "    val_mrr = np.mean(1/(np.where(np.argsort(val_pred)[:, ::-1] == y_val.reshape(-1, 1))[1]+1))\n",
    "    print(f'train mrr: {trn_mrr:.2f} | val mrr: {val_mrr:.2f}')\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train mrr: 0.47 | val mrr: 0.45"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
