{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, check_gpu, check_dir\n",
    "from clean_session import preprocess_sessions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import catboost as cat\n",
    "import matplotlib.pyplot as plt\n",
    "from clean_session import preprocess_sessions\n",
    "from manual_encoding import action_encoding, click_view_encoding, meta_encoding\n",
    "from hotel2vec import hotel2vec\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imp(data, fold_, plot_n=15):\n",
    "    check_dir('./imps')\n",
    "    imp = pd.DataFrame.from_records(data)\n",
    "    imp.to_csv(f'./imps/{fold_}.csv', index=False)\n",
    "    imp.columns = ['features', 'feature_importance']\n",
    "    imp_des = imp.sort_values(by='feature_importance', ascending=False)\n",
    "    imp_asc = imp.sort_values(by='feature_importance', ascending=True)\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(8, 8), nrows=2, ncols=1)\n",
    "    imp_des[:plot_n].plot(x='features', y='feature_importance', ax=axes[0], kind='barh', grid=True)\n",
    "    imp_asc[:plot_n].plot(x='features', y='feature_importance', ax=axes[1], kind='barh', grid=True)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('./imps/{}.png'.format(fold_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('train')#, nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>] Remove initial duplciates\n",
      "Before dropping duplicates df shape: (15932992, 12)\n",
      "After dropping duplicates df shape: (6683369, 12)\n",
      "[>>>>>][te=0.39 mins] Cliping session dataframe up to last click out (if there is clickout)\n",
      "[>>>>>][te=6.82 mins] filtering out sessions without clickouts, reference, or clickout is nan\n",
      "train length before filtering: 5,764,987\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = preprocess_sessions(train, data_source='train', rd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_last = train.groupby('session_id').last().reset_index()\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "drop_cols = ['user_id', 'timestamp', 'current_filters']\n",
    "train_last = train_last.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_last['impressions'] = train_last.impressions.str.split('|')\n",
    "train_last['prices'] = train_last.prices.str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "434*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_last[[c for c in train_last.columns if c!= 'impressions']].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_last.impressions\n",
    "# vals = train_last.impressions.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def explode(df):\n",
    "    impressions = df['impressions'].values.tolist()\n",
    "    prices = df['prices'].values.tolist()\n",
    "    \n",
    "    rs = [len(r) for r in impressions]\n",
    "    # locations\n",
    "    inds = np.concatenate([np.arange(i, dtype=int) for i in rs])\n",
    "    # relative locations\n",
    "    rel_inds = np.concatenate([np.arange(i)/i for i in rs])\n",
    "\n",
    "    # the rest cols\n",
    "    rest_cols = [c for c in df.columns if c not in ['impressions', 'prices']]\n",
    "    rest_arr = np.repeat(df[rest_cols].values, rs, axis=0)\n",
    "    # create dataframe to host the exploded\n",
    "    exploded = pd.DataFrame(np.column_stack((rest_arr, np.concatenate(impressions), np.concatenate(prices))),\n",
    "                            columns=rest_cols+['impression', 'price'])\n",
    "    exploded['price'] = exploded['price'].astype(int)\n",
    "    exploded['impression_loc'] = inds\n",
    "    exploded['rel_impression_loc'] = rel_inds\n",
    "    exploded['impression'] = exploded['impression'].astype(int)\n",
    "    exploded['reference'] = exploded['reference'].astype(int)\n",
    "    exploded['step'] = exploded['step'].astype(int)\n",
    "\n",
    "    return exploded\n",
    "\n",
    "df = explode(train_last)\n",
    "del train_last\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.impression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) all the manual encodings\n",
    "ae = action_encoding()\n",
    "ae_cols = [c for c in ae.columns if c != 'reference']\n",
    "df = pd.merge(df.set_index('impression'), ae.set_index('reference'), left_index=True, right_index=True)\n",
    "df.index.name = 'impression'\n",
    "df.reset_index(inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "# 2) the hotel2vec encodings\n",
    "hv = hotel2vec()\n",
    "hv_cols = [c for c in hv.columns if c != 'item_id']\n",
    "df = pd.merge(df.set_index('impression'), hv.set_index('item_id'), left_index=True, right_index=True)\n",
    "df.index.name = 'impression'\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# 3) click view\n",
    "cv = click_view_encoding()\n",
    "cv_cols = [c for c in cv.columns if c != 'item_id']\n",
    "df = pd.merge(df.set_index('impression'), cv.set_index('item_id'), left_index=True, right_index=True)\n",
    "df.index.name = 'impression'\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# 4) meta\n",
    "meta = meta_encoding()\n",
    "meta_cols = [c for c in meta.columns if c != 'item_id']\n",
    "df = pd.merge(df.set_index('impression'), meta.set_index('item_id'), left_index=True, right_index=True)\n",
    "df.index.name = 'impression'\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# df.groupby('session_id')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby('session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff(df, cols):\n",
    "    diff = (df.set_index('session_id')[cols] - grp[cols].mean()).reset_index(drop=True)\n",
    "    diff.columns = [f'{c}_diff' for c in diff.columns]\n",
    "    df = pd.concat([df, diff], axis=1)\n",
    "    return df\n",
    "\n",
    "df = compute_diff(df, ['price'])\n",
    "df = compute_diff(df, ae_cols)\n",
    "df = compute_diff(df, hv_cols)\n",
    "df = compute_diff(df, cv_cols)\n",
    "df = compute_diff(df, meta_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_cols = ['user_id', 'timestamp', 'current_filters']\n",
    "# df = df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target\n",
    "df['target'] = (df.reference == df.impression).astype(int)\n",
    "del df['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8243/434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()[df.isna().sum()!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode city, platform and device\n",
    "def categorize(df, cols):\n",
    "    for col in cols:\n",
    "        print('converting', col)\n",
    "        unique_values = df[col].unique()\n",
    "        mapping = {v: k for k, v in enumerate(unique_values)}\n",
    "        df[col] = df[col].map(mapping)\n",
    "cat_fts = ['city', 'platform', 'device', 'action_type', 'impression']\n",
    "categorize(df, cat_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes[df.dtypes=='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_per = 0.1\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "sids = df.session_id.values\n",
    "target = df.target.values\n",
    "del df['target']# train['timestamp'], train['session_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'GPU' if check_gpu() else 'CPU'\n",
    "params = {'iterations': 1000,\n",
    "          'learning_rate': 0.02,\n",
    "          'depth': 8,\n",
    "          'task_type': device,\n",
    "          'loss_function': 'MultiClass',\n",
    "          'eval_metric': 'Accuracy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trn_ind, val_ind in skf.split(sids, sids):\n",
    "    trn_mask = df.session_id.isin(sids[trn_ind])\n",
    "    del df['session_id']\n",
    "    x_trn, x_val = df[trn_mask], df[~trn_mask]\n",
    "    y_trn, y_val = target[trn_mask], target[~trn_mask]\n",
    "    \n",
    "    categorical_ind = [k for k, v in enumerate(x_trn.columns) if v in cat_fts]\n",
    "    \n",
    "    # train model\n",
    "    clf = cat.CatBoostClassifier(**params)\n",
    "    clf.fit(x_trn.values, y_trn,\n",
    "            cat_features=categorical_ind,\n",
    "            eval_set=(x_val.values, y_val),\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100,\n",
    "            plot=False)\n",
    "    print('Done!')\n",
    "    print('Grab feature importance for both train and val')\n",
    "    # get feature importance\n",
    "    trn_imp = clf.get_feature_importance(data=cat.Pool(data=x_trn, cat_features=categorical_ind),\n",
    "                                         prettified=True)\n",
    "    val_imp = clf.get_feature_importance(data=cat.Pool(data=x_val, cat_features=categorical_ind),\n",
    "                                         prettified=True)\n",
    "    plot_imp(trn_imp, 'train')\n",
    "    plot_imp(val_imp, 'val')\n",
    "    print('Done feature imp')\n",
    "    break\n",
    "#     # make prediction on validation set\n",
    "#     val_pred = clf.predict_proba(xval.values)[:, 1]\n",
    "#     logloss_i = log_loss(y_val, val_pred)\n",
    "#     # compute roc auc\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, val_pred, pos_label=1)\n",
    "#     auc_i = auc(fpr, tpr)\n",
    "#     # compute map\n",
    "#     map_i = average_precision_score(y_val, val_pred)\n",
    "#     print('logloss={0:.4f} | map={1:.4f} | auc={2:.4f}'.format(logloss_i, map_i, auc_i))\n",
    "\n",
    "#     # mrr\n",
    "#     print('reciproical rank for validation set')\n",
    "#     xval['pred'] = val_pred\n",
    "#     xval['target'] = y_val\n",
    "#     val_rr = xval.groupby(level=0).apply(reciprocal_rank)\n",
    "#     mrr = (1/val_rr[val_rr != 0]).mean()\n",
    "#     print(f'Mean reciporical rank on validation set: {mrr:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
